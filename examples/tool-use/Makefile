start-llama-cpp-server:
	llama-server -hf LiquidAI/LFM2-1.2B-Tool-GGUF --jinja --temp 0
